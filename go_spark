3/12/13

Something curious.  When I broke up kernel.cpp into multiple files for github prettiness, went from 1.93s -> 3.49s for 10k playouts.

I don't believe I changed anything other than this.  I did complilation in one big statement, but that should not matter.  Does breaking up the code really have that big of an effect?

=================================================================

3/7/13

Booyah.  Fixed up all mem leaks (launchSimKernel not freeing the state copy).  Now runs fast in constant mem

Also, realized all the clock I had to remove for OpenMP would have also caused the playout/sec timing to appear slow.  Removed them, now >5000k playouts per second. BOOSH

Need to get 64 bit primes working now, also check that they are actually detecting ko's occasionally.

http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/emt64.html

--------

More importantly, asked Fred to give me interface to his .so compilation, couldn't diving signature from kooky .h file.  Also asked him for avg.so, just so I have something easy to deal with.  Acutally asked on the 4/5


=========================================================================

3/6/13

The reason OpemMP was so slow was the system calls for rand() AND clock() are blocking.  Commenting them out relieved the burden.

Very visible in htop.  Before, processes were spending all their time in the kernel (red), now they are basically all green

weeeeeeeeeeeeeeeee

-------

Erg there is a memory leak.  I think it is the GoStateStruct, the MCTS_Nodes seem solid

working on writing explicit constructor but it is making things crash horribly...???

======================================================================

3/4/13

Got root parallelization almost working, architecture seems good, ran into some bugs:

Problem with doing MCTS search.  If we give it a 100 iterations, it seems to pick positions very close to the upper edge over and over again, even on an otherwise empty board.  100->1000 accentuates this problem.
Hypothesis is that it is something to do with domain->randomAction auto applying when we don't want it to???

NO!  For some reason, the scoreNode is assigning each node a 1 or 0 (this seems wrong, need to check).  Right now selecting the lower ix child with the max score, need to randomly select among the max.

Why were we smashing score into and int, wtf...

----------
NEW PROBLEM: using 4 threads takes 4 times as long as 1 thread.  This is useless.  With 'time ./kernel' there is a big system time component, suggesting there is some kind of locking going on

Some good links for this topic in the goby browser folder.  Have ruled out (I think):
	1 rand issue, implemented getRandom from post, nonblocking
        2 false sharing issue, increase size of MCTS_Node
          (not sure if doing what I think, mem usage very similar despite 		  100 fold size increase
        3 Tried locking each thread to a processor.  

No improvement.  
Not using and std data structures like the one post, really puzzled as to why there is such a slowdown.  Am I calling OMP right? 

----------------
Also, need to write method to merge the trees, then decide.

---------------------------------------------------------------------

Right, some performance opts.  Basically inlined the two calls to neighborsOf2() floodFill.  Gave decent improvement

Re-instituted the MAX_MOVE limit count.  This helped to, now up to about 4,000/sec

======================================================================

2/27/13

Constructing test examples for OpenMP (omp.cpp)

Invesitgating dynamic memory allocation for building separate trees
Should be no probl

Working on do the parallel impl, all of a sudden launchSimKernel on 19x19
is twice as slow as before.  Cannot figure out where the difference came from

not g++ vs nvcc
not fix in setBoard concerning empty_intersections...

WHAHAHAHTTTTTT?

---fuck.  it was because of the error in the new bitmask.  Since it wasn't updating the size, and capture() depended on it, no caputures were happing and the game was super short, that's why it was so fast

also, why is applyAction taking so long outside of floodFill?

oh well, keep moving on parallel
try to integrate fred's compiled stuff

=====================================================================

2/26/13

Talked with Fred.  Gameplan

1) Integrate Value function with MCTS.  Can do by either MATLAB->exe compiliing and then linking, or re-write MATLAB code in C and use directly.
Try option 1 (wait until built on Linux machine, not Mac).  Also get CPU root parallelization working.  Evaluate whether this is better than random and UCT.  His code is 19x19 only

2) Value iteration comes second.  GPU might lend itself nicely here, would force the rewrite.

---------------------------------------------------------
State of the Code

-randomAction is both out of whack between __device__ and __host__
-still need 64 bit Zobrist hashing, mersenneTwister to generate Rands
-smaller board rep nice, but necessary? (yes if going to get to value iteration)
-simplifiy 1 and 2 versions of function to just the best one

did some cleanup and commenting


=====================================================================

2/20/13

More performance.  Implemented the smarter randomAction scheme, got a huge payoff at memory cost.  Maintaining the empty_intersections is mem expensive, and adds over head to freeze,thaw, setBoard but really streamlines finding a random move.

Somehow applyAction (not its children???? wtf) is taking up the time right now.  not sure if interpreting gprof correctly.  BitMask::set is not far behind, owing to all the division and moding at each step.  

Taking out the connected_to_lib logic actually gave a slight speedup , turns out overhead not worth it

Inlined isSuicide into applyAction, gave some opportunities to avoid redundant work, and some short circuiting

Changed bitmask implementation to bool[].  50% faster, as don't need to do so many divides and mods.  Again paying a big space tradeoff

Right now 19x19 sits at just under 5KB.  Can sim 10000 boards in 2-3 secs, depending on how you count. 3.5 - 5k boards a second


=========================================================

2/19/13

To generate 64 bit randoms for Zobrist hashing:  
http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/VERSIONS/C-LANG/mt19937-64.c

randomAction still taking the longest time.  There should be a way to leverage empty_intersections across calls.  (for that matter, empty_intersections should be declared and allocated in .h file anyway, start by making this change anyway. use int8_t)
Then, if nothing is captured by move placement, can reuse empty_intersections and board_ix.  
Else, add the captured (now empty) ixs that have a lower index than the empty pos that was swapped and returned (the new captures that appear after will be gotten to when we need to)

This should be mega faster

Also, put isSuicide inline into applyAction, doesn't get called anywhere else and should be able to reduce the number of neighbor calls

--------------------

Implemented new eye logic per fred's email

uncovered bug, not sure if related, where enemy won't play single spot surrounded by opp color even though it will capture
##fixed

on a related note, say white filled the board except for one spot.  if black played there it would capture.  how can we avoid this?

==============================================================================================

some edits got lost here?

===============================================================

2/9/13

The most time is now spent in random action, presumable iterating through the entire board and randomly shuffling it before testing legality is slow.  Have sped up 2x by being lazy about the Fisher-Yates in-place shuffle.  That is, we generate a random number between 0 and num_empty.  If this falls outside the range of empty values discovered in board, we need to iterate through the board some more add find more empties.  Once we have enough, do the swap and test for legality.  If it fails, we iterate on the empty array with the just failed intersection chopped off the end.  But now, when we generate a rand, it is more likely to fall within our range.  This way, the expected number of positions we need to iterate through on the board, as well as the number of rands and swaps we need to do, is reduced because we stop doing it once an acceptable intersection is found.

=============================================================

2/7/13

Wrestling with floodFill somemore, changed only have one bitMask.  Use another to use results of previous fill when filling neighbor.  For example, if a flood fill from the East neighb runs into stones already explored on the North neighbors FF, we can know for free that the east neighbor string won't be captured.

So BM get and set are being called less, but applyAction is now called ~3 times more often. why?

Maybe related to fact that randomAction doesn't seem to be passing soon enough.  It just sits there spinning its wheels before starting a new game

Also, do short circuit of applyAction that doesn't have to call floodFill, freezeBoard.  i.e all neighbs empty or same  color => auto place if side_effects if true, then done.

Also, if legal already false, don't need to do other test.  Whcih one first though?

--------------

short circuited apply Action
sped up freeze/thawBoard with memcpy
fixed issue with PASS moves not being applied

20k playout / 6s

Further:

can take out adding self stone to isSuicide flood fills, obviated by self short circuiting in applyAction(are you sure?)
can use getNeighbors2 in isSuicide
can avoid hist check if move already illegal

================================================================


2/6/13

Fixed prob with applyAction not rolling back illegal moves

BitMask set and Queue are taking up all the time, what to do?

=============================================================================================

2/5/13

Optimizing wise, 
	-need to fix randomAction (see the 28th)                check
	-fit board rep into bits
	-merge getNeighbors and filter into one unit            check
	-applyAction doesn't need an array, just a bit mask     check
	-give bit masks a length counter                        check

Right, so we are looking at two parallization paths:

1) CPU - root parallelization
	-should be straightforward application of OpenMP pramas.  No shared memory to worry about

2) GPU - leaf parallelization
	-can speed up randomAction by finding obvious legal and illegal moves in parallel, then testing complicated captures in sequence
	- but really applyAction, specifically floodFill, is where the most work is being done
		-TODO: profile to make sure this is really were the bottleneck is
		- speed up repeated filter neighbors action as per above (can be parallelized gains seem miniscule compared to payoff)
		- parallelize floodFill
			- create floodFill kernel, where multiple threads pop intersections off the queue, and add appropriate neighbors onto the queue
				-necessitate locking the queue for safety (but not the BitMasks 'marked' and 'onqueue' because they read or go 0->1)
					-lock struct can be built with atomicAnd()
			- could create one block per opp_color neighbor that needs to be tested for capture (would require separate BitMasks and return booleans, how does work intradevice?)
			-Overhead outweigh the cost?
			
3) GPU - global memory datastructure for more efficient liberty determination
	- not sure how would work, how much more efficient would be


Proposed Lock impl:

lock = false
not_held[num_threads] = [True,...]		

def acquire(thread_id) {
	while( not_held[thread_id] ){
		not_held[thread_id] = atomicAnd( lock, true )
	}
	return
}

=============================================================================================================================================


1/31/13

Good ref here: http://developer.download.nvidia.com/CUDA/training/NVIDIA_GPU_Computing_Webinars_CUDA_Memory_Optimization.pdf

Why wait for GPU to finish playouts before continuing to explore tree?  Better would be asynch, so the CPU keeps doing selection moves.  When the GPU is done
computing the playouts from the previous one, have backprop handler execute?  Not algorithmically precise, but perhaps not a big deal.

cudaMallocHost() ?? pinned host memory (what does this imply, exactly?)

test performance of global vs shared somehow


Started working on integrating threads, can now have multiple threads in block without seg fault
	- still need work on constructors to make warnings go away, this is low priority though

Have the following ideas for speedup:

randomAction : 
	each thread checks an intersection for simple illegality
		-not occupied, not surrounded by kin
		- mark if def legal as well
	randomly shuffle the indices into two groups, def legal and unsure
	while not found legal
		random()
		if rand num falls in def legal, return a member from this group
		else start testing someone from unsure group (maintain walker ix to iterate in order)

applyAction
	have switch to avoid simple eye checking if implicitly already done in randomAction
	have each thread check if has complaining intersection:
		abuts an enemy
		has no liberties
		didn't complain last time
	for each new complainer:
		floodFill to check libs
		if no libs:
			if same color : illegal, return false
			else : capture and keep going (do anything to old_complainer bitmask here?)

	REALLY NEED TO ANALYZE THIS ALGO MORE CAREFULLY, ESP with respect to complainers and captures



=========================================================================================================

1/30/13

Talked to Michael Arnold about GPU. He wants to hava a more complete characterization of them, especially regarding memory access (global vs shared)
So I need to cobble together some sources

Also we need to drill down the algorithms that are relevant here and figure out what can go in parallel.  Perhaps send him the randomAction, applyAction code and formalize the idea of the parallel legal-move checking.

=========================================================================================================

1/29/13

--ptxas-options=-v : reports shared memory per block


========================================================================================================

1/28/13

Will be meeting with Fred and guy to compare my impl to the one discussed here:
http://article.gmane.org/gmane.games.devel.go/20027/match=gpu+go

He got 47,000 playouts per second!? wtf.  I am getting ~600.  Are we measuring different things
or have I done something dumb?  The only real gains I can see are to use Zobrist hashing to compare past states.
But surely this will not be enough....

So made a few improvements:
1) randomAction can be configured to auto-apply the first legal action it comes across
	-whoops this conflicts with the exclusion set.  No matter, need to redo logic for speed-up anyway (see smarterRandomAction for deet, sadly sRA isn't truly random
2) Zobrist Hashing for superko checking
3) simplified rewards calculation to utilize the fact that only single eyes will be open empty when play concludes (by construction)

This got almost a 2x speed up, still a longway off the 47x was looking for :)

TODO: fix/optimize randomAction.  Consider storing open positions in a way that can be randomly sampled (mem loss prob not worth it, got a 8->7 sec when using smarter randomAction, and that is as good sampling a new data structure would be)

Need to do more testing of GPU, not entirely sure it's all working correctly

use deviceQuery for spec's for meeting

use occupancy calculator for more numbers



==================================================================================================

1/27/13

Making high level slides for meeting with that guy at Salk Fred mentioned

TODO: in randomAction(), check for exclusion before doing legality test
TODO: Zobrist hashes rather than storing the past boards explicitly, can improve Ko checking
TODO: root parallelization


===================================================================================================

1/24/13

new direction is to pursue root parallelization
openmp vs boost::threads
	- since will need very little (none) communication between MCTS trees, OpenMP should be easiest
	- can email jack about OpenMP
probably want to fork repo again and remove all CUDA/nvcc related stuff?

Read up on RI learning, fred says I can prob skip chapters 1-3.  
Want to work through DP, MC, then TD approaches

perhaps will need to put some slides together on base code approach by next week


